{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GANでピカチュウを描いてみる\n",
    "\n",
    "## TL;DR\n",
    "\n",
    "`GAN(Generative Adversarial Network)`でピカチュウを描いてみるというネタです。\n",
    "* googleでポケモンの画像を集める。\n",
    "* ピカチュウの画像を`CNN`で選定する。\n",
    "* `GAN`でピカチュウを描く。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 環境\n",
    "\n",
    "### 言語/フレームワーク\n",
    "\n",
    "* Python\n",
    "* keras\n",
    "* tensorflow\n",
    "* Jupyter Notebook\n",
    "\n",
    "### ハードウェア\n",
    "\n",
    "* CPU: 4Core 3.4GHz\n",
    "* MEM: 24GB\n",
    "* GPU: GTX1060 6GB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## googleでポケモンの画像を集める\n",
    "\n",
    "データセットとして大量のピカチュウの画像が必要です。\n",
    "今回は、googleを利用して画像データを集めます。\n",
    "\n",
    "### google-image-downloadのインストールと設定\n",
    "\n",
    "[google-images-download](https://github.com/hardikvasa/google-images-download)を使用します。\n",
    "以下でインストールします。\n",
    "\n",
    "```sh\n",
    "pip install google_images_download\n",
    "```\n",
    "\n",
    "`chromedriver`がインストールされていない場合は、先にインストールします。\n",
    "Macでbrewを使う場合は以下のコマンドを実行します。\n",
    "\n",
    "```sh\n",
    "brew cask install chromdriver\n",
    "```\n",
    "\n",
    "`chromedriver`のパスを確認します。\n",
    "\n",
    "```sh\n",
    "which chromedriver\n",
    "```\n",
    "\n",
    "### 画像の収集\n",
    "\n",
    "画像の収集を行います。\n",
    "`google-images-download`で100個以上のイメージを取得する場合は、`chromedriver`のパスの指定が必要です。\n",
    "今回は最大で`10000`件集めます。\n",
    "\n",
    "上記で確認した`chromedriver`のパスを指定します。私の環境では`/usr/local/bin/chromedriver`でした。\n",
    "\n",
    "```sh\n",
    "googleimagesdownload --keywords \"ピカチュウ,Pikachu,ポケモン,Pokemon\" -l 10000 --chromedriver /usr/local/bin/chromedriver\n",
    "```\n",
    "\n",
    "`downloads`という名前のディレクトリの下に、`--keywords`で指定したキーワード別にディレクトリが作成されて、関連する画像が以下の様にダウンロードされます。\n",
    "\n",
    "![](images/2018-09-16 10-13-34.png)\n",
    "\n",
    "今回は合計で4195件の画像が見つかりました。\n",
    "\n",
    "### 画像の切り出し\n",
    "\n",
    "後工程の処理では、正方形の画像の方が簡単であるため、集めた画像を`PILLOW`を利用して切り出します。\n",
    "ここでは一旦`256x256`の画像として切り出しています。\n",
    "\n",
    "```python\n",
    "import os\n",
    "import glob\n",
    "from PIL import Image, ImageOps\n",
    "\n",
    "input_dirname = os.path.join('..', 'downloads', '*', '*')\n",
    "output_dirname = os.path.join('..', 'dataset', 'reshaped')\n",
    "files = glob.glob(input_dirname)\n",
    "reshaped_size = (256, 256)\n",
    "\n",
    "for i, file in enumerate(files):\n",
    "    index = i + 1\n",
    "    try:\n",
    "        image = Image.open(file)\n",
    "    except IOError:\n",
    "        pass\n",
    "    reshaped = ImageOps.fit(image, reshaped_size, Image.NEAREST)\n",
    "    converted = reshaped.convert('RGB')\n",
    "    converted.save(os.path.join(output_dirname, f'{index}.jpg'))\n",
    "    print(f'{index}: {file} was saved.')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ピカチュウの画像をCNNで選定する\n",
    "\n",
    "ピカチュウの画像の選定も機会に行わせたいと思います。\n",
    "が、教師データの抽出は人が行う必要があります。\n",
    "\n",
    "今回は以下のように、`dataset/labeled`というディレクトリの下に、学習用と検証用のデータセットを手動で選択しておきました。\n",
    "\n",
    "![](images/2018-09-16 10-25-30.png)\n",
    "\n",
    "`trains`が学習用、`valids`が検証用のデータセットです。\n",
    "ピカチュウの画像を選ぶのが目的ですが、ピカチュウとそれ以外の2項分類とするため、教師データもピカチュウとそれ以外を用意しています。手動で選んだ数はそれぞれ以下の通りです。\n",
    "\n",
    "* trains-pikachu: 30件\n",
    "* trains-others: 50件\n",
    "* valids-pikachu: 12件\n",
    "* validas-others: 20件\n",
    "\n",
    "### ニューラルネットワークの構造\n",
    "\n",
    "NNの構造は以下の通りです。CNNを利用したスタンダードなものです。\n",
    "\n",
    "![](images/2018-09-16 10-40-00.png)\n",
    "\n",
    "### データセットの準備とImage Augmentation\n",
    "\n",
    "学習に使用するデータセットはkerasの`ImageDataGenerator`で読み込みます。\n",
    "`ImageDataGenerator`はデータセットの読み込み時に、サイズの変更や数値データのリスケーリングだけではなｋ、`Image Augmentation`として画像を変形した水増しを行うことができます。\n",
    "\n",
    "以下は、読み込んだ画像を`Image Augmentation`により水増ししながら、学習用データセットとして準備する際のコードです。ちなみに検証用データセットは`Image Augmentation`による水増しは行いません(水増しするのは学習するためのバリエーションを増やすためで、答えを増やすためではありません)。\n",
    "\n",
    "```python\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img\n",
    "import os\n",
    "\n",
    "trains_dirname = os.path.join('..', 'dataset', 'labeled', 'trains')\n",
    "valids_dirname = os.path.join('..', 'dataset', 'labeled', 'valids')\n",
    "trains_generator = ImageDataGenerator(\n",
    "    rescale=1 / 255,\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    channel_shift_range=20.0,\n",
    "    #shear_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=False\n",
    "    )\n",
    "valids_generator = ImageDataGenerator()\n",
    "\n",
    "trains_generator = trains_generator.flow_from_directory(\n",
    "    trains_dirname,\n",
    "    target_size=(32,32),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n",
    "valids_generator = valids_generator.flow_from_directory(\n",
    "    valids_dirname,\n",
    "    target_size=(32,32),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n",
    "```\n",
    "\n",
    "### 学習の実行\n",
    "\n",
    "データセットの準備が整ったら学習を開始します。epochを100としていますが、10回程度で結果が収束(ここでは`val_loss`を観測しているので、`val_loss`が下がらなくなる状態)すると思います。\n",
    "\n",
    "```python\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "\n",
    "model_filename = os.path.join('models', 'finding-pikachu_model_{val_loss:.2f}.h5')\n",
    "\n",
    "model.fit_generator(\n",
    "    trains_generator,\n",
    "    validation_data=valids_generator,\n",
    "    steps_per_epoch=100,\n",
    "    epochs=100,\n",
    "    callbacks = [\n",
    "        TensorBoard(log_dir='tflogs'),\n",
    "        EarlyStopping(patience=3, monitor='val_loss'),\n",
    "        ModelCheckpoint(model_filename, monitor='val_loss', save_best_only=True),\n",
    "    ]\n",
    ")\n",
    "```\n",
    "\n",
    "私の環境では7回目で学習が完了しました。\n",
    "\n",
    "```\n",
    "Epoch 6/100\n",
    "100/100 [==============================] - 9s 92ms/step - loss: 0.1193 - acc: 0.9600 - mean_absolute_error: 0.0719 - val_loss: 1.0682e-07 - val_acc: 1.0000 - val_mean_absolute_error: 0.0000e+00\n",
    "Epoch 7/100\n",
    "100/100 [==============================] - 8s 83ms/step - loss: 0.0993 - acc: 0.9672 - mean_absolute_error: 0.0604 - val_loss: 1.0682e-07 - val_acc: 1.0000 - val_mean_absolute_error: 0.0000e+00\n",
    "```\n",
    "\n",
    "### ピカチュウ探し\n",
    "\n",
    "学習したモデルを利用して、全4200枚のポケモン画像からピカチュウを探し出します。\n",
    "\n",
    "```python\n",
    "import glob\n",
    "import os\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "import shutil\n",
    "\n",
    "predicting_dirname = os.path.join('..', 'dataset', 'reshaped', '*')\n",
    "predicted_dirname = os.path.join('..', 'dataset', 'predicted_auto2')\n",
    "for i, file in enumerate(glob.glob(predicting_dirname)):\n",
    "    image =load_img(file).resize((32, 32))\n",
    "    array = img_to_array(image) / 255\n",
    "    predicted = model.predict(np.array([\n",
    "        array\n",
    "    ]))\n",
    "    prob = int(predicted[0][0]*100)\n",
    "    print(f'file={file}, pikachu?={prob}%')\n",
    "    \n",
    "    if prob >= 99:\n",
    "        shutil.copy(file, predicted_dirname)\n",
    "```\n",
    "\n",
    "学習したモデルが99%以上ピカチュウだと判断した画像を、ピカチュウとして選定しました。\n",
    "\n",
    "![](images/2018-09-16 11-03-45.png)\n",
    "\n",
    "うーん、全部ピカチュウ!\n",
    "\n",
    "![](images/2018-09-16 11-06-18.png)\n",
    "\n",
    "あつまったピカチュウの画像は724枚でした。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GANでピカチュウを描く\n",
    "\n",
    "`GAN`により、機械が集めたピカチュウの画像を学習し、ピカチュウの画像を新しく描くということを行います。\n",
    "\n",
    "### そもそもGANって?\n",
    "\n",
    "`Generative Adversarial Network`です。日本語では`敵対的生成ネットワーク`と言います。具体的にははQiitaの[今さら聞けないGAN（1）　基本構造の理解](https://qiita.com/triwave33/items/1890ccc71fab6cbca87e)を参照するのがいいと思います。\n",
    "簡単に言うと、乱数を元に偽物の画像を生成するモデルと、教師データを元に真偽を見破るモデルの2つを対決させ、より本物に近い画像を生成する、あるいはより真偽の判定の精度を上げるという仕組みです。\n",
    "\n",
    "これぞAIという感じで兆かっこいい!!\n",
    "\n",
    "今回は偽物の画像を生成するモデルを育てる目的で使用します。\n",
    "\n",
    "### ニューラルネットワークの構造\n",
    "\n",
    "#### generator(偽造側)\n",
    "\n",
    "![](images/2018-09-16 11-25-00.png)\n",
    "\n",
    "#### discriminator(見破る側)\n",
    "\n",
    "![](images/2018-09-16 11-27-00.png)\n",
    "\n",
    "### keras-adversarialの利用\n",
    "\n",
    "`GAN`の学習は偽造側と見破る側の両方を学習させながら進める必要があるため、kerasを利用してもコードが複雑になります。\n",
    "その辺りの面倒を見てくれるモジュールとして、今回は[keras-adversarial](https://github.com/bstriner/keras-adversarial)を利用します。\n",
    "\n",
    "ただし、[keras-adversarial](https://github.com/bstriner/keras-adversarial)は、そのままではkeras 2.1.6以上では動作しません。\n",
    "keras 2.1.6以上を利用する場合は、以下のパッチを適用する必要があります。\n",
    "\n",
    "* https://github.com/bstriner/keras-adversarial/pull/59/commits/a1d783adf3f1934df63cc0970494f655b40e957f\n",
    "\n",
    "### 学習の実行\n",
    "\n",
    "基本的には`Antonio Gulli, Sujit Pal「直感 Deep Learning」オライリー・ジャパン, 2018`に掲載されていたコードを元にしています。\n",
    "違いは以下の点です。\n",
    "\n",
    "* `Conv2D`の代わりに、`SeparableConv2D`を利用している。\n",
    "* Unit数の定義を`nch=256`ではなく、`nch=512`としている。\n",
    "* カーネルサイズを`h=5`ではなく、`h=7`としている。\n",
    "\n",
    "epochは50001回です。100epoch毎に`generator`が生成した画像を保存しました。\n",
    "\n",
    "```python\n",
    "    example_gan(AdversarialOptimizerSimultaneous(), \"generated/pikachu\",\n",
    "                opt_g=Adam(1e-4, decay=1e-5),\n",
    "                opt_d=Adam(1e-3, decay=1e-5),\n",
    "                nb_epoch=50001, generator=generator, discriminator=discriminator,\n",
    "                latent_dim=latent_dim)\n",
    "```\n",
    "\n",
    "### generatorが生成した画像\n",
    "\n",
    "最も精度が高かった(ここではdiscriminator側のlossが最低だった状態)25,200epoch目の画像は以下の通りです。\n",
    "\n",
    "![](images/epoch-25200.png)\n",
    "\n",
    "以下は最初のepochから25,200epoch目までの変化です。\n",
    "\n",
    "![](images/epoch-0-25200.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 所感\n",
    "\n",
    "社内で機械学習に興味を持ってもらうための教材としてやってみましたが、要求されるハードウェア性能が高く、気軽に誰でもという訳にはいかなそうです。ただ、機械学習の深淵に触れるための入り口として非常に面白い題材だと感じました。\n",
    "\n",
    "`RTX20180Ti`でも買って、`PGGAN(Progressive Growing of GANs)`とか手を出してみようかなと思ったり・・・。\n",
    "\n",
    "なお、実は`GANでギャンを描く`というのを最初に思いついたのですが、[先駆者](http://blog.asilla.jp/entry/gan-and-gyan)がいらっしゃったので、ピカチュウに変更しました。\n",
    "でも、`ギャン`が`GAN`の入門になるというのも面白そうなので、今後試してみようと思います。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参考文献\n",
    "\n",
    "* Antonio Gulli, Sujit Pal「直感 Deep Learning」オライリー・ジャパン, 2018\n",
    "* [keras-adversarial](https://github.com/bstriner/keras-adversarial)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
